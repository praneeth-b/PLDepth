{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabd668a-5d9b-4ac7-a991-f96bddd2f628",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PurelyMaskedRandomSamplingStrategy' from 'pldepth.data.sampling' (/home/praneeth/projects/thesis/git/PLDepth/pldepth/data/sampling.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e2f119ba7a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhr_wsi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHRWSITFDataAccessObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataset_type_by_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhourglass_provider\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHourglassLargeScaleDataProvider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThresholdedMaskedRandomSamplingStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInformationScoreBasedSampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDepthLossType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/thesis/git/PLDepth/pldepth/data/providers/hourglass_provider.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFDatasetDataProvider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThresholdedMaskedRandomSamplingStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPurelyMaskedRandomSamplingStrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpldepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDepthLossType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PurelyMaskedRandomSamplingStrategy' from 'pldepth.data.sampling' (/home/praneeth/projects/thesis/git/PLDepth/pldepth/data/sampling.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pldepth.data.dao.hr_wsi import HRWSITFDataAccessObject\n",
    "from pldepth.data.io_utils import get_dataset_type_by_name\n",
    "from pldepth.data.providers.hourglass_provider import HourglassLargeScaleDataProvider\n",
    "from pldepth.data.sampling import ThresholdedMaskedRandomSamplingStrategy, InformationScoreBasedSampling\n",
    "from pldepth.losses.losses_meta import DepthLossType\n",
    "from pldepth.losses.nll_loss import HourglassNegativeLogLikelihood\n",
    "from pldepth.models.PLDepthNet import get_pl_depth_net\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.callbacks import TerminateOnNaN, LearningRateScheduler\n",
    "from pldepth.models.pl_hourglass import EffNetFullyFledged\n",
    "from pldepth.losses.nll_loss import HourglassNegativeLogLikelihood\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pldepth.util.env import init_env\n",
    "from pldepth.models.models_meta import ModelParameters, get_model_type_by_name\n",
    "from pldepth.util.training_utils import LearningRateScheduleProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290d270-0963-4b0d-ac99-eaf667a4eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"HR-WSI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671ad4c-d488-4612-ad4c-5abc5bb825f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('/home/praneeth/projects/thesis/git/bakup/PLDepth/pldepth/weights/150821-230138model_rnd_sampling.h5',\n",
    "                                       custom_objects={'EffNetFullyFledged': EffNetFullyFledged},\n",
    "                                                  compile=False)\n",
    "model2 = tf.keras.models.load_model('/home/praneeth/projects/thesis/git/bakup/PLDepth/pldepth/weights/160821-022846mod_info_sampling3.h5',\n",
    "                                       custom_objects={'EffNetFullyFledged': EffNetFullyFledged},\n",
    "                                                  compile=False)\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a37d31-fdfd-4763-a8c3-ec9ffde01552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_shape = [448, 448, 3]\n",
    "data_path = '/home/praneeth/projects/thesis/git/HR-WSI/'\n",
    "\n",
    "dao = HRWSITFDataAccessObject(data_path, model_input_shape, seed=42)\n",
    "val_imgs_ds, val_gts_ds, val_cons_masks = dao.get_validation_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5caad0-10a4-4bd3-b6d2-452813c74354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vds = list(val_imgs_ds.as_numpy_iterator())\n",
    "vgt = list(val_gts_ds.as_numpy_iterator())\n",
    "test_img = vds[:50]\n",
    "test_gt = vgt[:50]\n",
    "np.array(test_gt[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f5074-4138-4e90-9791-5491ca8be4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,5)) \n",
    "plt.imshow(vds[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e915f2-859c-4960-a73a-5e1eb103ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model1.predict(np.array([vds[3]]), batch_size=None)\n",
    "out2 = model2.predict(np.array([vds[3]]), batch_size=None)\n",
    "\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01796283-ed06-4bf4-b22f-0acc2dc23e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6)) \n",
    "plt.imshow(out1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93dfab-bb98-4fb5-b19d-65d2525c3a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6)) \n",
    "plt.imshow(out2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702c3be-36d0-4b70-ad79-45fead6bee10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e8225-78b3-4f4c-872f-a1ccf7fb0b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = np.random.choice(list(range(448*448)), 10, replace=False)\n",
    "# print(idx)\n",
    "# idx0, idx1 = np.split(idx,2)\n",
    "# print(idx0, idx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd03c31-53bc-40ac-92fc-a132d320184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_error(op, gt, imsize=(448,448), num=100):\n",
    "    np.random.seed(10)\n",
    "    idx = np.random.choice(list(range(imsize[0]*imsize[1])), num*2, replace=False)  # add seed or np random state\n",
    "    idx0, idx1 = np.split(idx, 2)\n",
    "    op_flat = op.flatten()\n",
    "    gt_flat = gt.flatten()\n",
    "    \n",
    "    out_order = np.greater(op_flat[idx0], op_flat[idx1])\n",
    "    gt_order = np.greater(gt_flat[idx0], gt_flat[idx1])\n",
    "    accuracy = np.equal(out_order, gt_order).sum()/num\n",
    "    return 1 - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de103e49-97a9-4cfd-af34-07c0299e5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_vec1 = []\n",
    "for i in  range(len(test_img)):\n",
    "    pred = model1.predict(np.array([test_img[i]]), batch_size=None)\n",
    "    err = ordinal_error(pred[0], test_gt[i])\n",
    "    err_vec1.append(err)\n",
    "    \n",
    "np.mean(err_vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88a066-dc32-415c-8d30-57c0568556c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_vec2 = []\n",
    "for i in  range(len(test_img)):\n",
    "    pred = model2.predict(np.array([test_img[i]]), batch_size=None)\n",
    "    err = ordinal_error(pred[0], test_gt[i])\n",
    "    err_vec2.append(err)\n",
    "    \n",
    "np.mean(err_vec2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f559d-7160-40b4-9e7a-33db8d8238a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b1317-3762-4729-a8bc-db2129a546e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from skimage import data, img_as_float\n",
    "# from skimage.segmentation import chan_vese\n",
    "\n",
    "# image = vds[3]\n",
    "\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# print(np.amax(image))\n",
    "# print(image.shape)\n",
    "# #plt.imshow(image)\n",
    "# image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "# #image = cv2.equalizeHist(image.astype(np.uint8))\n",
    "\n",
    "\n",
    "# # Feel free to play around with the parameters to see how they impact the result\n",
    "# cv = chan_vese(image, mu=0.5, lambda1=1, lambda2=1, tol=1e-3,\n",
    "#                max_iter=100, dt=0.5, init_level_set=\"checkerboard\",\n",
    "#                extended_output=True)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(8, 8))\n",
    "# ax = axes.flatten()\n",
    "\n",
    "# ax[0].imshow(image, cmap=\"gray\")\n",
    "# ax[0].set_axis_off()\n",
    "# ax[0].set_title(\"Original Image\", fontsize=12)\n",
    "\n",
    "# ax[1].imshow(cv[0], cmap=\"gray\")\n",
    "# ax[1].set_axis_off()\n",
    "# title = \"Chan-Vese segmentation - {} iterations\".format(len(cv[2]))\n",
    "# ax[1].set_title(title, fontsize=12)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7136e-13b2-4755-b901-cb2cfec86117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6)) \n",
    "# plt.imshow(out1[0])\n",
    "# im2 = cv2.normalize(out1[0], None, 0, 255, cv2.NORM_MINMAX)\n",
    "# nv = chan_vese(im2, mu=0.35, lambda1=1, lambda2=1, tol=1e-3,\n",
    "#                max_iter=200, dt=0.5, init_level_set=\"checkerboard\",\n",
    "#                extended_output=True)\n",
    "\n",
    "# plt.imshow(nv[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de111fd8-c3b3-4b80-a359-a26141164983",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.normalize(out1[0], None, 0,255, cv2.NORM_MINMAX), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52ade0-2a8b-47af-8158-4bd19a316ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    print(\"threshold is \", lower, \"and\", upper)\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "\n",
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=3.0, threshold=0):\n",
    "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
    "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
    "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
    "    sharpened = sharpened.round().astype(np.uint8)\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
    "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "    return sharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076cce9-b1f2-4280-a1de-ed6cf2ab3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_o = vds[3]\n",
    "img_o = cv2.cvtColor(img_o, cv2.COLOR_RGB2GRAY)\n",
    "img_o = cv2.normalize(img_o, None, 0 ,255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "img_o = cv2.medianBlur(img_o,15)  #cv2.blur(img_o, ksize=(7,7))\n",
    "# Using the Canny filter to get contours\n",
    "edges_o = cv2.Canny(img_o, 50, 140)\n",
    "in_edges= auto_canny(img_o)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(in_edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c90816-96e3-4fe6-a197-a695c4611e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im_out = out1[0]\n",
    "im_out = cv2.normalize(im_out, None, 0,255, cv2.NORM_MINMAX)\n",
    "im_sharp = unsharp_mask(im_out)\n",
    "cv2.normalize(im_sharp, None, 0 , 255, cv2.NORM_MINMAX)\n",
    "\n",
    "pred_edges =  auto_canny(im_sharp)\n",
    "plt.imshow(pred_edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15b5ff-89ce-4aac-a03b-48692b015b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import hausdorff_distance\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def splitImage(img, n=14):\n",
    "    \"\"\" image is broken into nxn pieces\n",
    "    \"\"\"\n",
    "    split = [0]*(n*n) #np.zeros(n*n)\n",
    "    n = int(img.shape[0]/n)\n",
    "    i=0\n",
    "    for r in range(0,img.shape[0],n):\n",
    "        for c in range(0,img.shape[1],n):\n",
    "            sm_img = img[r:r+n, c:c+n]\n",
    "            split[i] = sm_img\n",
    "            i += 1\n",
    "            \n",
    "    #plt.imshow(sm_img, cmap= 'gray')\n",
    "    return np.array(split)\n",
    "    \n",
    "    \n",
    "def hausdorf_dist(i1, i2):\n",
    "    \"\"\" return hausdorf dist + the points at max distance\"\"\"\n",
    "    \n",
    "    return hausdorff_distance(i1, i2)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def hausdorff_pair(image0, image1):\n",
    "    \"\"\" Returns the coordinates of the points at hausdorff distance\"\"\"\n",
    "\n",
    "    a_points = np.transpose(np.nonzero(image0))\n",
    "    b_points = np.transpose(np.nonzero(image1))\n",
    "\n",
    "    # If either of the sets are empty, there is no corresponding pair of points\n",
    "    if len(a_points) == 0 or len(b_points) == 0:\n",
    "        warnings.warn(\"One or both of the images is empty.\", stacklevel=2)\n",
    "        return (), ()\n",
    "\n",
    "    nearest_dists_from_b, nearest_a_point_indices_from_b = cKDTree(a_points).query(b_points)\n",
    "    nearest_dists_from_a, nearest_b_point_indices_from_a = cKDTree(b_points) \\\n",
    "        .query(a_points)\n",
    "\n",
    "    max_index_from_a = nearest_dists_from_b.argmax()\n",
    "    max_index_from_b = nearest_dists_from_a.argmax()\n",
    "\n",
    "    max_dist_from_a = nearest_dists_from_b[max_index_from_a]\n",
    "    max_dist_from_b = nearest_dists_from_a[max_index_from_b]\n",
    "\n",
    "    if max_dist_from_b > max_dist_from_a:\n",
    "        return a_points[max_index_from_b], \\\n",
    "            b_points[nearest_b_point_indices_from_a[max_index_from_b]]\n",
    "    else:\n",
    "        return a_points[nearest_a_point_indices_from_b[max_index_from_a]], \\\n",
    "            b_points[max_index_from_a]\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badee743-bcd6-4663-8e83-ed232b3d82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def active_sampling(in_edges, pred_edges):\n",
    "\n",
    "    split_in = splitImage(in_edges)\n",
    "    split_pred = splitImage(pred_edges)\n",
    "    dist = np.zeros(split_in.shape[0])\n",
    "    pts =  np.zeros((split_in.shape[0],2))\n",
    "\n",
    "    for i in range(split_in.shape[0]):\n",
    "        hd = hausdorf_dist(split_in[i], split_pred[i])\n",
    "        pt_in , pt_pred = hausdorff_pair(split_in[i], split_pred[i])\n",
    "        #print(pt_in)\n",
    "\n",
    "        if not len(pt_in) == 0:\n",
    "            st_r = (int(i/14) * split_in.shape[1]) + pt_in[0]\n",
    "            st_c = int((i % 14) * split_in.shape[2] + pt_in[1])\n",
    "            dist[i] = hd\n",
    "            pts[i] = np.array([st_r, st_c])\n",
    "\n",
    "        else:\n",
    "            st_r = int(i/14) * int(split_in.shape[1]) \n",
    "            st_c = int((i % 14)* split_in.shape[2]) \n",
    "            dist[i] = 1000\n",
    "            pts[i] = np.array([st_r, st_c])\n",
    "\n",
    "\n",
    "    #sorting the hausdorf dist\n",
    "    idx = np.argsort(dist)\n",
    "    dist = dist[idx]\n",
    "    pts = pts[idx]\n",
    "    pos = pts[:,0]*448 + pts[:,1]\n",
    "\n",
    "    return pos.astype(np.uint32), pts.astype(np.uint32)\n",
    "\n",
    "#pos, pos_xy = active_sampling(in_edges, pred_edges)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63543e9f-c72a-46c5-a23b-4c16a364a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def oracle(img, img_gts, pos_xy):\n",
    "    list_size=5\n",
    "    result_buffer = np.zeros([int(pos_xy.shape[0]/list_size), list_size, 2], dtype=np.float32)\n",
    "    buf = np.zeros((list_size,2))\n",
    "    \n",
    "    np.random.shuffle(pos_xy)\n",
    "    j=0\n",
    "    for i in range(0, pos_xy.shape[0]-list_size, list_size):\n",
    "        \n",
    "        for k in range(list_size):\n",
    "            buf[k,0] = pos_xy[i+k,0]*448 + pos_xy[i+k,1]\n",
    "            buf[k,1] = gts[tuple(pos[i+k])]\n",
    "        \n",
    "        result_buffer[j] = buf\n",
    "        j+=1\n",
    "        \n",
    "    return result_buffer\n",
    "    \n",
    "    \n",
    "    \n",
    "def active_learning_data_provider(img_arr, img_gts_arr, model, batch_size):\n",
    "    \n",
    "    a_ds_in = list(img_arr.as_numpy_iterator())\n",
    "    a_gt_in = list(img_gts_arr.as_numpy_iterator())\n",
    "    \n",
    "    a_ds_out = []\n",
    "    sample_lists = np.zeros([len(a_ds_in), 196, 5])   # samples per img(14x14), ranking size\n",
    "    \n",
    "    i=0\n",
    "    for img_in, gts_in in zip(a_ds_in, a_gt_in):\n",
    "        \n",
    "        img_o = cv2.cvtColor(img_in, cv2.COLOR_RGB2GRAY)\n",
    "        img_o = cv2.normalize(img_o, None, 0 ,255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        img_o = cv2.medianBlur(img_o,15)  #cv2.blur(img_o, ksize=(7,7))\n",
    "        # Using the Canny filter to get contours\n",
    "        in_edges= auto_canny(img_o)\n",
    "        \n",
    "        pred_ele = model.predict(np.array([img_in]), batch_size=None)\n",
    "        pred_ele = np.squeeze(pred_ele)\n",
    "        pred_im_out = cv2.normalize(pred_ele, None, 0,255, cv2.NORM_MINMAX)\n",
    "        pred_im_sharp = unsharp_mask(im_out)\n",
    "\n",
    "        pred_edges =  auto_canny(pred_im_sharp)\n",
    "        \n",
    "        pos, pos_xy = active_sampling(in_edges, pred_edges)\n",
    "        \n",
    "        sample_lists[i] = oracle(img_in, img_gts, pos_xy)\n",
    "        \n",
    "    sample_list_tf = tf.data.Dataset.from_tensor_slices(sample_lists)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tf.data.Dataset.zip((img_arr, sample_list_tf)).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a1bb6-2709-42c2-b571-ff730a5032f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "448/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37125937-3a62-4d33-bccb-9519f45d67d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
